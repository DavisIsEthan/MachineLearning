{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports \n",
    "from pathlib import Path\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization, Bidirectional, Reshape, TimeDistributed\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from pymms.sdc import mrmms_sdc_api as mms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import os\n",
    "import time\n",
    "import sklearn\n",
    "import scipy\n",
    "import pickle\n",
    "import random\n",
    "import requests\n",
    "import sys\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "###tf.compat.v1.disable_v2_behavior() ### Only for old CUDA version usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set filepath and import data csv\n",
    "fpath = 'C:/Users/Davis/Desktop/'\n",
    "fname = 'MSBrandNewData' + '.csv'\n",
    "file = fpath+fname\n",
    "mms_data = pd.read_csv(file, index_col=0, infer_datetime_format=True, parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set index and pop off the \"selected\" column. The T/F value indicates if a SITL selected the timestep. \n",
    "### We pop this column because we don't want selections data interpolated a little later\n",
    "index = mms_data.index\n",
    "selections = mms_data.pop(\"selected\")\n",
    "column_names = mms_data.columns\n",
    "\n",
    "### It's a little later. We rid the data of garbage and interpolate\n",
    "mms_data = mms_data.replace([np.inf, -np.inf], np.nan)\n",
    "mms_data = mms_data.interpolate(method='time', limit_area='inside')\n",
    "\n",
    "### The data is scaled to have zero mean and std dev of 1, courtest of sci-kit learn\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "### Put everything back together nicely in a Pandas dataframe\n",
    "mms_data = scaler.fit_transform(mms_data)\n",
    "mms_data = pd.DataFrame(mms_data, index, column_names)\n",
    "mms_data = mms_data.join(selections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-kitchen",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Because there are far more points not selected than selected, weighting them equally would\n",
    "### give us garbage out. Thus we weight based on their portion of all points \n",
    "false_weight = len(mms_data)/(2*np.bincount(mms_data['selected'].values)[0])\n",
    "true_weight = len(mms_data)/(2*np.bincount(mms_data['selected'].values)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-allah",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Organize the data into SITL windows, which are contiguous\n",
    "sitl_windows = mms.mission_events('sroi', mms_data.index[0].to_pydatetime(), mms_data.index[-1].to_pydatetime(), sc='mms1')\n",
    "windows = []\n",
    "for start, end in zip(sitl_windows['tstart'], sitl_windows['tend']):\n",
    "  window = mms_data[start:end]\n",
    "  if not window.empty and len(window[window['selected']==True])>1:\n",
    "    windows.append(window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-pierre",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Divide the data into training and testing data, ~70% in train, ~30% in test\n",
    "while True:\n",
    "    X_train, X_test, y_train, y_test = [], [], [], []\n",
    "\n",
    "    sequences = []\n",
    "    for i in range(len(windows)):\n",
    "      X_sequence = []\n",
    "      y_sequence = []\n",
    "\n",
    "      if random.random() < 0.7:\n",
    "        for value in windows[i].values:\n",
    "          X_sequence.append(value[:-1])\n",
    "          y_sequence.append(value[-1])\n",
    "          if len(X_sequence) == SEQ_LEN:\n",
    "            X_train.append(X_sequence.copy())\n",
    "            \n",
    "            y_train.append(y_sequence.copy())\n",
    "\n",
    "            X_sequence = []\n",
    "            y_sequence = []\n",
    "\n",
    "      else:\n",
    "        for value in windows[i].values:\n",
    "          X_sequence.append(value[:-1])\n",
    "          y_sequence.append(value[-1])\n",
    "          if len(X_sequence) == SEQ_LEN:\n",
    "            X_test.append(X_sequence.copy())\n",
    "            \n",
    "            y_test.append(y_sequence.copy())\n",
    "\n",
    "            X_sequence = []\n",
    "            y_sequence = []\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.expand_dims(np.array(y_train), axis=2)\n",
    "    y_test = np.expand_dims(np.array(y_test), axis=2)\n",
    "\n",
    "    if len(X_train) > len(X_test):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check how organizing went\n",
    "print(f\"Number of sequences in training data: {len(X_train)}\")\n",
    "print(f\"Number of sequences in test data: {len(X_test)}\")\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate F1 score\n",
    "# (Credit: Paddy and Kev1n91 from https://stackoverflow.com/a/45305384/3988976)\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We use weighted binary crossentropy as it gives more weight to positive classes when large amount of outputs are zero\n",
    "# (Credit: tobigue from https://stackoverflow.com/questions/42158866/neural-network-for-multi-label-classification-with-large-number-of-classes-outpu)\n",
    "def weighted_binary_crossentropy(target, output):\n",
    "    \"\"\"\n",
    "    Weighted binary crossentropy between an output tensor \n",
    "    and a target tensor. POS_WEIGHT is used as a multiplier \n",
    "    for the positive targets.\n",
    "\n",
    "    Combination of the following functions:\n",
    "    * keras.losses.binary_crossentropy\n",
    "    * keras.backend.tensorflow_backend.binary_crossentropy\n",
    "    * tf.nn.weighted_cross_entropy_with_logits\n",
    "    \"\"\"\n",
    "     # transform back to logits\n",
    "    _epsilon = tf.convert_to_tensor(K.epsilon(), output.dtype.base_dtype)\n",
    "    output = tf.clip_by_value(output, _epsilon, 1 - _epsilon)\n",
    "    output = tf.math.log(output / (1 - output))\n",
    "    # compute weighted loss\n",
    "    #target = tf.cast(target)\n",
    "    loss = tf.nn.weighted_cross_entropy_with_logits(labels=target,\n",
    "                                                    logits=output,\n",
    "                                                    pos_weight=true_weight)\n",
    "    return tf.reduce_mean(loss, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Epochs, batch size, sequence legnth\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 72\n",
    "SEQ_LEN = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-conducting",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set up our model\n",
    "\n",
    "model_name = f\"{SEQ_LEN}-SEQ_LEN-{BATCH_SIZE}-BATCH_SIZE-{LAYER_SIZE}-LAYER_SIZE-{int(time.time())}\"\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Bidirectional(LSTM(LAYER_SIZE, return_sequences=True), input_shape= (None, X_train.shape[2])))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Bidirectional(LSTM(LAYER_SIZE, return_sequences=True), input_shape= (None, X_train.shape[2])))\n",
    "\n",
    "model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "\n",
    "opt = tf.keras.optimizers.SGD()\n",
    "\n",
    "model.compile(loss = weighted_binary_crossentropy,\n",
    "        optimizer=opt,\n",
    "        metrics=['accuracy', f1, tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "model.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-ribbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set filepath and model training checkpoints\n",
    "filepath = \"C:/Users/Davis/Desktop/ms-dl-davisMSSGDv27.model\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_f1', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train and test the model\n",
    "history = model.fit(\n",
    "  x=X_train, y=y_train,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  epochs=EPOCHS,\n",
    "  validation_data=(X_test, y_test),\n",
    "  callbacks=[checkpoint],\n",
    "  verbose=1,\n",
    "  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-surrey",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot loss of the model on training and testing data as a function of training epoch\n",
    "plt.plot(history.history['loss']) ### training\n",
    "plt.plot(history.history['val_loss'])  ### testing\n",
    "plt.title('Model Training Loss vs. Testing Loss by Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'testing'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot F1 score on training and testing data as a function of training epoch\n",
    "plt.plot(history.history['f1'])\n",
    "plt.plot(history.history['val_f1'])\n",
    "plt.title('Model Training F1 vs. Testing F1 by Epoch')\n",
    "plt.ylabel('F1')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'testing'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot precision on training and testing data as a function of training epoch\n",
    "plt.plot(history.history['precision'])\n",
    "plt.plot(history.history['val_precision'])\n",
    "plt.title('Model Training Precision vs. Testing Precision by Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'testing'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-signal",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot model accuracy on training and testing data as a function of training epoch\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Training accuracy vs. accuracy by Epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'testing'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-month",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load validation data\n",
    "validation_data = pd.read_csv('C:/Users/Davis/Desktop/MSNewData.csv', index_col=0, infer_datetime_format=True, parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the model\n",
    "model = tf.keras.models.load_model('C:/Users/Davis/Desktop/ms-dl-davisMSSGDv27.model', {'weighted_binary_crossentropy':weighted_binary_crossentropy, 'f1':f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocess validation data in the same way as training/testing data previously\n",
    "scaler = preprocessing.StandardScaler()\n",
    "index = validation_data.index\n",
    "selections = validation_data.pop('selected')\n",
    "column_names = validation_data.columns\n",
    "\n",
    "validation_data = validation_data.replace([np.inf, -np.inf], np.nan)\n",
    "validation_data = validation_data.interpolate(method='time', limit_area='inside')\n",
    "\n",
    "validation_data = scaler.fit_transform(validation_data)\n",
    "validation_data = pd.DataFrame(validation_data, index, column_names)\n",
    "validation_data = validation_data.join(selections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-intention",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Assign data and selections to X and Y, respectively\n",
    "validation_X = np.asarray(validation_data.values[:,:-1])\n",
    "validation_y = np.asarray(validation_data.values[:,-1])\n",
    "\n",
    "### TensorFlow doesn't agree with the data unless it is reshaped\n",
    "validation_X = validation_X[:, np.newaxis, :]\n",
    "validation_y = validation_y[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-familiar",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test the model\n",
    "test_predictions = model.predict(validation_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-convenience",
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop = 'C:/Users/Davis/Desktop/' ### Filepath declaration\n",
    "\n",
    "### Plot Ground Truth predictions\n",
    "plt.figure(figsize=(28, 5))\n",
    "plt.plot(validation_y.astype(int))\n",
    "plt.title(\"Ground Truth (SITL) Selections by Datapoint - Magnetosphere\")\n",
    "plt.ylabel('Selected (1) or not (0)')\n",
    "plt.xlabel('Datapoint')\n",
    "plt.savefig(desktop + 'SWSITL.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-northeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot model's predictions\n",
    "plt.figure(figsize=(28, 5))\n",
    "plt.plot(test_predictions.flatten())\n",
    "plt.title(\"Model Predicted Selections by Datapoint - Solar Wind\")\n",
    "plt.ylabel('Selection confidence (continous)')\n",
    "plt.xlabel('Datapoint')\n",
    "plt.savefig(desktop + 'SWModel.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot only predictions made with greater than 50% confidence\n",
    "t_output = [0 if x < 0.5 else 1 for x in test_predictions.flatten()]\n",
    "plt.figure(figsize=(28, 5))\n",
    "plt.plot(t_output)\n",
    "plt.title(\"Filtered Model Predictions by Datapoint - Solar Wind\")\n",
    "plt.ylabel('Selected (1) or not (0)')\n",
    "plt.xlabel('Datapoints')\n",
    "plt.savefig(desktop + 'SWFiltered.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-sheffield",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocess data for ROC \n",
    "y_eval = validation_y.astype(int)\n",
    "y_eval = y_eval.flatten()\n",
    "\n",
    "y_true = (np.asarray(t_output)).squeeze()\n",
    "y_true = y_true.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create ROC\n",
    "plt.figure(figsize = (10, 6))\n",
    "fpr, tpr, thresholds = roc_curve(y_eval, y_true)\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Solar Wind ROC curve - AUC = {:.2f}'.format(auc(fpr, tpr)))\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(desktop + 'SWROCCurve.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create confusion matrix\n",
    "cm = confusion_matrix(y_eval, t_output)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
